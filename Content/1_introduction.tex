Autonomous vehicles are getting much press nowadays and Google have previously
estimated that they will have a fully functional car on the road within 5 years
(cite nature). While autonomous cars might reduce the risk of traffic accidents,
many have previously pointed out the ethical problems of when they do get in a
traffic accident --- who is to be held responsible?

Even if the car is assumed to be perfect scenarios will arise when a collision
will be unavoidable and the car forced to choose one of several possible bad
outcomes.

Autonomous vehicles can be categorized into several different categories, of
most interest would be those categorized as ``level 4'', which are fully
autonomous cars that would require nothing of the driver. A level 4 car would be
one that has no steering wheel, no pedals and require nothing of the driver;
anyone from a child to a blind person could use the car.

Yet for fully autonomous cars the problem of responsibility is very unclear,
as there is no driver and the passengers might not have the possibility of
preventing an accident.
